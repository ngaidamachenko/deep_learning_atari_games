{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the DQN Network with convolutional layers for image input\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, action_dim):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(4, 32, kernel_size=8, stride=4)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
    "        self.fc1 = nn.Linear(7*7*64, 512)\n",
    "        self.fc2 = nn.Linear(512, action_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.squeeze(1)\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up the Pacman environment\n",
    "env = gym.make('MsPacman-v4')\n",
    "#number of possible actions dimensions\n",
    "action_dim = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize primary & target DQN networks\n",
    "dqn = DQN(action_dim)\n",
    "target_dqn = DQN(action_dim)\n",
    "target_dqn.load_state_dict(dqn.state_dict()) #copying weights from primary to target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up the optimizer (Adam) with a learning rate of 0.00025\n",
    "optimizer = optim.Adam(dqn.parameters(), lr=0.00025)\n",
    "#Define the loss function (Huber Loss or Smooth L1 Loss)\n",
    "loss_fn = nn.SmoothL1Loss()\n",
    "\n",
    "#Discount factor for future rewards\n",
    "gamma = 0.99\n",
    "#Initial epsilon (exploration rate)\n",
    "epsilon = 1.0\n",
    "#Epsilon decay rate after each episode\n",
    "epsilon_decay = 0.995\n",
    "#Exploration progression rate\n",
    "epsilon_min = 0.1\n",
    "#Memory buffer to store experiences\n",
    "memory = []\n",
    "#Maximum number of experiences to keep in memory\n",
    "max_memory = 10000\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "episodes = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess the image\n",
    "def preprocess(image):\n",
    "    #Convert image to grayscale\n",
    "    image = Image.fromarray(image).convert('L')\n",
    "    image = image.resize((84, 84))\n",
    "    #Convert to numpy array and normalize the pixel values\n",
    "    image = np.array(image) / 255.0\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to select an action using epsilon-greedy policy\n",
    "def select_action(state, epsilon):\n",
    "    if random.random() < epsilon:\n",
    "        return env.action_space.sample()\n",
    "    else:\n",
    "        state = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            return dqn(state).argmax().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to train the DQN using mini-batch from the memory buffer\n",
    "def train():\n",
    "    if len(memory) < batch_size:\n",
    "        return\n",
    "    \n",
    "    batch = random.sample(memory, batch_size)\n",
    "    state_batch, action_batch, reward_batch, next_state_batch, done_batch = zip(*batch)\n",
    "    \n",
    "    state_batch = torch.FloatTensor(np.array(state_batch)).to(device)\n",
    "    action_batch = torch.LongTensor(action_batch).unsqueeze(1).to(device)\n",
    "    reward_batch = torch.FloatTensor(reward_batch).to(device)\n",
    "    next_state_batch = torch.FloatTensor(np.array(next_state_batch)).to(device)\n",
    "    done_batch = torch.FloatTensor(done_batch).to(device)\n",
    "    \n",
    "    q_values = dqn(state_batch).gather(1, action_batch)\n",
    "    next_q_values = target_dqn(next_state_batch).max(1)[0].unsqueeze(1)\n",
    "    \n",
    "    expected_q_values = reward_batch.unsqueeze(1) + gamma * next_q_values * (1 - done_batch.unsqueeze(1))\n",
    "\n",
    "    loss = loss_fn(q_values, expected_q_values.detach())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multi-tier reward function\n",
    "def adjust_reward(reward, info):\n",
    "    #Refer to game info for actions\n",
    "    if 'pellet_captured' in info:\n",
    "        reward += 1  #Low-tier reward for capturing a regular pellet\n",
    "    if 'power_pellet_captured' in info:\n",
    "        reward += 30  #Mid-tier reward for capturing a power pellet\n",
    "    if 'all_pellets_captured' in info:\n",
    "        reward += 100  #High-tier reward for capturing all pellets\n",
    "    if 'ghost_caught' in info:\n",
    "        reward -= 50  #Negative reward for being caught by a ghost\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPU boost\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dqn.to(device)\n",
    "target_dqn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0, Total Reward: 190.0, Epsilon: 0.9950\n",
      "Episode: 1, Total Reward: 210.0, Epsilon: 0.9900\n",
      "Episode: 2, Total Reward: 1100.0, Epsilon: 0.9851\n",
      "Episode: 3, Total Reward: 190.0, Epsilon: 0.9801\n",
      "Episode: 4, Total Reward: 260.0, Epsilon: 0.9752\n",
      "Episode: 5, Total Reward: 120.0, Epsilon: 0.9704\n",
      "Episode: 6, Total Reward: 170.0, Epsilon: 0.9655\n",
      "Episode: 7, Total Reward: 340.0, Epsilon: 0.9607\n",
      "Episode: 8, Total Reward: 230.0, Epsilon: 0.9559\n",
      "Episode: 9, Total Reward: 250.0, Epsilon: 0.9511\n",
      "Episode: 10, Total Reward: 100.0, Epsilon: 0.9464\n",
      "Episode: 11, Total Reward: 150.0, Epsilon: 0.9416\n",
      "Episode: 12, Total Reward: 240.0, Epsilon: 0.9369\n",
      "Episode: 13, Total Reward: 210.0, Epsilon: 0.9322\n",
      "Episode: 14, Total Reward: 200.0, Epsilon: 0.9276\n",
      "Episode: 15, Total Reward: 180.0, Epsilon: 0.9229\n",
      "Episode: 16, Total Reward: 190.0, Epsilon: 0.9183\n",
      "Episode: 17, Total Reward: 160.0, Epsilon: 0.9137\n",
      "Episode: 18, Total Reward: 200.0, Epsilon: 0.9092\n",
      "Episode: 19, Total Reward: 240.0, Epsilon: 0.9046\n",
      "Episode: 20, Total Reward: 280.0, Epsilon: 0.9001\n",
      "Episode: 21, Total Reward: 140.0, Epsilon: 0.8956\n",
      "Episode: 22, Total Reward: 190.0, Epsilon: 0.8911\n",
      "Episode: 23, Total Reward: 270.0, Epsilon: 0.8867\n",
      "Episode: 24, Total Reward: 180.0, Epsilon: 0.8822\n",
      "Episode: 25, Total Reward: 120.0, Epsilon: 0.8778\n",
      "Episode: 26, Total Reward: 210.0, Epsilon: 0.8734\n",
      "Episode: 27, Total Reward: 160.0, Epsilon: 0.8691\n",
      "Episode: 28, Total Reward: 180.0, Epsilon: 0.8647\n",
      "Episode: 29, Total Reward: 250.0, Epsilon: 0.8604\n",
      "Episode: 30, Total Reward: 190.0, Epsilon: 0.8561\n",
      "Episode: 31, Total Reward: 250.0, Epsilon: 0.8518\n",
      "Episode: 32, Total Reward: 230.0, Epsilon: 0.8475\n",
      "Episode: 33, Total Reward: 130.0, Epsilon: 0.8433\n",
      "Episode: 34, Total Reward: 230.0, Epsilon: 0.8391\n",
      "Episode: 35, Total Reward: 240.0, Epsilon: 0.8349\n",
      "Episode: 36, Total Reward: 170.0, Epsilon: 0.8307\n",
      "Episode: 37, Total Reward: 190.0, Epsilon: 0.8266\n",
      "Episode: 38, Total Reward: 210.0, Epsilon: 0.8224\n",
      "Episode: 39, Total Reward: 280.0, Epsilon: 0.8183\n",
      "Episode: 40, Total Reward: 300.0, Epsilon: 0.8142\n",
      "Episode: 41, Total Reward: 240.0, Epsilon: 0.8102\n",
      "Episode: 42, Total Reward: 190.0, Epsilon: 0.8061\n",
      "Episode: 43, Total Reward: 370.0, Epsilon: 0.8021\n",
      "Episode: 44, Total Reward: 170.0, Epsilon: 0.7981\n",
      "Episode: 45, Total Reward: 210.0, Epsilon: 0.7941\n",
      "Episode: 46, Total Reward: 260.0, Epsilon: 0.7901\n",
      "Episode: 47, Total Reward: 210.0, Epsilon: 0.7862\n",
      "Episode: 48, Total Reward: 210.0, Epsilon: 0.7822\n",
      "Episode: 49, Total Reward: 230.0, Epsilon: 0.7783\n",
      "Episode: 50, Total Reward: 200.0, Epsilon: 0.7744\n",
      "Episode: 51, Total Reward: 350.0, Epsilon: 0.7705\n",
      "Episode: 52, Total Reward: 120.0, Epsilon: 0.7667\n",
      "Episode: 53, Total Reward: 230.0, Epsilon: 0.7629\n",
      "Episode: 54, Total Reward: 250.0, Epsilon: 0.7590\n",
      "Episode: 55, Total Reward: 170.0, Epsilon: 0.7553\n",
      "Episode: 56, Total Reward: 360.0, Epsilon: 0.7515\n",
      "Episode: 57, Total Reward: 200.0, Epsilon: 0.7477\n",
      "Episode: 58, Total Reward: 140.0, Epsilon: 0.7440\n",
      "Episode: 59, Total Reward: 140.0, Epsilon: 0.7403\n",
      "Episode: 60, Total Reward: 590.0, Epsilon: 0.7366\n",
      "Episode: 61, Total Reward: 240.0, Epsilon: 0.7329\n",
      "Episode: 62, Total Reward: 220.0, Epsilon: 0.7292\n",
      "Episode: 63, Total Reward: 220.0, Epsilon: 0.7256\n",
      "Episode: 64, Total Reward: 350.0, Epsilon: 0.7219\n",
      "Episode: 65, Total Reward: 160.0, Epsilon: 0.7183\n",
      "Episode: 66, Total Reward: 290.0, Epsilon: 0.7147\n",
      "Episode: 67, Total Reward: 290.0, Epsilon: 0.7112\n",
      "Episode: 68, Total Reward: 230.0, Epsilon: 0.7076\n",
      "Episode: 69, Total Reward: 140.0, Epsilon: 0.7041\n",
      "Episode: 70, Total Reward: 210.0, Epsilon: 0.7005\n",
      "Episode: 71, Total Reward: 230.0, Epsilon: 0.6970\n",
      "Episode: 72, Total Reward: 190.0, Epsilon: 0.6936\n",
      "Episode: 73, Total Reward: 300.0, Epsilon: 0.6901\n",
      "Episode: 74, Total Reward: 140.0, Epsilon: 0.6866\n",
      "Episode: 75, Total Reward: 200.0, Epsilon: 0.6832\n",
      "Episode: 76, Total Reward: 180.0, Epsilon: 0.6798\n",
      "Episode: 77, Total Reward: 260.0, Epsilon: 0.6764\n",
      "Episode: 78, Total Reward: 220.0, Epsilon: 0.6730\n",
      "Episode: 79, Total Reward: 190.0, Epsilon: 0.6696\n",
      "Episode: 80, Total Reward: 300.0, Epsilon: 0.6663\n",
      "Episode: 81, Total Reward: 650.0, Epsilon: 0.6630\n",
      "Episode: 82, Total Reward: 380.0, Epsilon: 0.6597\n",
      "Episode: 83, Total Reward: 350.0, Epsilon: 0.6564\n",
      "Episode: 84, Total Reward: 210.0, Epsilon: 0.6531\n",
      "Episode: 85, Total Reward: 300.0, Epsilon: 0.6498\n",
      "Episode: 86, Total Reward: 470.0, Epsilon: 0.6466\n",
      "Episode: 87, Total Reward: 150.0, Epsilon: 0.6433\n",
      "Episode: 88, Total Reward: 160.0, Epsilon: 0.6401\n",
      "Episode: 89, Total Reward: 280.0, Epsilon: 0.6369\n",
      "Episode: 90, Total Reward: 290.0, Epsilon: 0.6337\n",
      "Episode: 91, Total Reward: 320.0, Epsilon: 0.6306\n",
      "Episode: 92, Total Reward: 240.0, Epsilon: 0.6274\n",
      "Episode: 93, Total Reward: 290.0, Epsilon: 0.6243\n",
      "Episode: 94, Total Reward: 380.0, Epsilon: 0.6211\n",
      "Episode: 95, Total Reward: 250.0, Epsilon: 0.6180\n",
      "Episode: 96, Total Reward: 280.0, Epsilon: 0.6149\n",
      "Episode: 97, Total Reward: 160.0, Epsilon: 0.6119\n",
      "Episode: 98, Total Reward: 190.0, Epsilon: 0.6088\n",
      "Episode: 99, Total Reward: 250.0, Epsilon: 0.6058\n",
      "Episode: 100, Total Reward: 290.0, Epsilon: 0.6027\n",
      "Episode: 101, Total Reward: 440.0, Epsilon: 0.5997\n",
      "Episode: 102, Total Reward: 270.0, Epsilon: 0.5967\n",
      "Episode: 103, Total Reward: 260.0, Epsilon: 0.5937\n",
      "Episode: 104, Total Reward: 360.0, Epsilon: 0.5908\n",
      "Episode: 105, Total Reward: 200.0, Epsilon: 0.5878\n",
      "Episode: 106, Total Reward: 290.0, Epsilon: 0.5849\n",
      "Episode: 107, Total Reward: 350.0, Epsilon: 0.5820\n",
      "Episode: 108, Total Reward: 330.0, Epsilon: 0.5790\n",
      "Episode: 109, Total Reward: 320.0, Epsilon: 0.5762\n",
      "Episode: 110, Total Reward: 320.0, Epsilon: 0.5733\n",
      "Episode: 111, Total Reward: 340.0, Epsilon: 0.5704\n",
      "Episode: 112, Total Reward: 490.0, Epsilon: 0.5676\n",
      "Episode: 113, Total Reward: 240.0, Epsilon: 0.5647\n",
      "Episode: 114, Total Reward: 240.0, Epsilon: 0.5619\n",
      "Episode: 115, Total Reward: 280.0, Epsilon: 0.5591\n",
      "Episode: 116, Total Reward: 320.0, Epsilon: 0.5563\n",
      "Episode: 117, Total Reward: 240.0, Epsilon: 0.5535\n",
      "Episode: 118, Total Reward: 330.0, Epsilon: 0.5507\n",
      "Episode: 119, Total Reward: 160.0, Epsilon: 0.5480\n",
      "Episode: 120, Total Reward: 260.0, Epsilon: 0.5452\n",
      "Episode: 121, Total Reward: 210.0, Epsilon: 0.5425\n",
      "Episode: 122, Total Reward: 230.0, Epsilon: 0.5398\n",
      "Episode: 123, Total Reward: 310.0, Epsilon: 0.5371\n",
      "Episode: 124, Total Reward: 310.0, Epsilon: 0.5344\n",
      "Episode: 125, Total Reward: 360.0, Epsilon: 0.5318\n",
      "Episode: 126, Total Reward: 240.0, Epsilon: 0.5291\n",
      "Episode: 127, Total Reward: 240.0, Epsilon: 0.5264\n",
      "Episode: 128, Total Reward: 210.0, Epsilon: 0.5238\n",
      "Episode: 129, Total Reward: 290.0, Epsilon: 0.5212\n",
      "Episode: 130, Total Reward: 230.0, Epsilon: 0.5186\n",
      "Episode: 131, Total Reward: 200.0, Epsilon: 0.5160\n",
      "Episode: 132, Total Reward: 260.0, Epsilon: 0.5134\n",
      "Episode: 133, Total Reward: 360.0, Epsilon: 0.5108\n",
      "Episode: 134, Total Reward: 210.0, Epsilon: 0.5083\n",
      "Episode: 135, Total Reward: 290.0, Epsilon: 0.5058\n",
      "Episode: 136, Total Reward: 200.0, Epsilon: 0.5032\n",
      "Episode: 137, Total Reward: 230.0, Epsilon: 0.5007\n",
      "Episode: 138, Total Reward: 320.0, Epsilon: 0.4982\n",
      "Episode: 139, Total Reward: 330.0, Epsilon: 0.4957\n",
      "Episode: 140, Total Reward: 650.0, Epsilon: 0.4932\n",
      "Episode: 141, Total Reward: 260.0, Epsilon: 0.4908\n",
      "Episode: 142, Total Reward: 250.0, Epsilon: 0.4883\n",
      "Episode: 143, Total Reward: 210.0, Epsilon: 0.4859\n",
      "Episode: 144, Total Reward: 370.0, Epsilon: 0.4834\n",
      "Episode: 145, Total Reward: 590.0, Epsilon: 0.4810\n",
      "Episode: 146, Total Reward: 380.0, Epsilon: 0.4786\n",
      "Episode: 147, Total Reward: 280.0, Epsilon: 0.4762\n",
      "Episode: 148, Total Reward: 260.0, Epsilon: 0.4738\n",
      "Episode: 149, Total Reward: 210.0, Epsilon: 0.4715\n",
      "Episode: 150, Total Reward: 270.0, Epsilon: 0.4691\n",
      "Episode: 151, Total Reward: 210.0, Epsilon: 0.4668\n",
      "Episode: 152, Total Reward: 350.0, Epsilon: 0.4644\n",
      "Episode: 153, Total Reward: 270.0, Epsilon: 0.4621\n",
      "Episode: 154, Total Reward: 960.0, Epsilon: 0.4598\n",
      "Episode: 155, Total Reward: 180.0, Epsilon: 0.4575\n",
      "Episode: 156, Total Reward: 250.0, Epsilon: 0.4552\n",
      "Episode: 157, Total Reward: 170.0, Epsilon: 0.4529\n",
      "Episode: 158, Total Reward: 290.0, Epsilon: 0.4507\n",
      "Episode: 159, Total Reward: 310.0, Epsilon: 0.4484\n",
      "Episode: 160, Total Reward: 250.0, Epsilon: 0.4462\n",
      "Episode: 161, Total Reward: 290.0, Epsilon: 0.4440\n",
      "Episode: 162, Total Reward: 310.0, Epsilon: 0.4417\n",
      "Episode: 163, Total Reward: 380.0, Epsilon: 0.4395\n",
      "Episode: 164, Total Reward: 620.0, Epsilon: 0.4373\n",
      "Episode: 165, Total Reward: 320.0, Epsilon: 0.4351\n",
      "Episode: 166, Total Reward: 200.0, Epsilon: 0.4330\n",
      "Episode: 167, Total Reward: 290.0, Epsilon: 0.4308\n",
      "Episode: 168, Total Reward: 250.0, Epsilon: 0.4286\n",
      "Episode: 169, Total Reward: 290.0, Epsilon: 0.4265\n",
      "Episode: 170, Total Reward: 690.0, Epsilon: 0.4244\n",
      "Episode: 171, Total Reward: 350.0, Epsilon: 0.4223\n",
      "Episode: 172, Total Reward: 250.0, Epsilon: 0.4201\n",
      "Episode: 173, Total Reward: 270.0, Epsilon: 0.4180\n",
      "Episode: 174, Total Reward: 230.0, Epsilon: 0.4159\n",
      "Episode: 175, Total Reward: 330.0, Epsilon: 0.4139\n",
      "Episode: 176, Total Reward: 340.0, Epsilon: 0.4118\n",
      "Episode: 177, Total Reward: 220.0, Epsilon: 0.4097\n",
      "Episode: 178, Total Reward: 330.0, Epsilon: 0.4077\n",
      "Episode: 179, Total Reward: 330.0, Epsilon: 0.4057\n",
      "Episode: 180, Total Reward: 240.0, Epsilon: 0.4036\n",
      "Episode: 181, Total Reward: 590.0, Epsilon: 0.4016\n",
      "Episode: 182, Total Reward: 340.0, Epsilon: 0.3996\n",
      "Episode: 183, Total Reward: 670.0, Epsilon: 0.3976\n",
      "Episode: 184, Total Reward: 390.0, Epsilon: 0.3956\n",
      "Episode: 185, Total Reward: 600.0, Epsilon: 0.3936\n",
      "Episode: 186, Total Reward: 410.0, Epsilon: 0.3917\n",
      "Episode: 187, Total Reward: 400.0, Epsilon: 0.3897\n",
      "Episode: 188, Total Reward: 390.0, Epsilon: 0.3878\n",
      "Episode: 189, Total Reward: 340.0, Epsilon: 0.3858\n",
      "Episode: 190, Total Reward: 570.0, Epsilon: 0.3839\n",
      "Episode: 191, Total Reward: 320.0, Epsilon: 0.3820\n",
      "Episode: 192, Total Reward: 460.0, Epsilon: 0.3801\n",
      "Episode: 193, Total Reward: 950.0, Epsilon: 0.3782\n",
      "Episode: 194, Total Reward: 170.0, Epsilon: 0.3763\n",
      "Episode: 195, Total Reward: 390.0, Epsilon: 0.3744\n",
      "Episode: 196, Total Reward: 460.0, Epsilon: 0.3725\n",
      "Episode: 197, Total Reward: 410.0, Epsilon: 0.3707\n",
      "Episode: 198, Total Reward: 430.0, Epsilon: 0.3688\n",
      "Episode: 199, Total Reward: 570.0, Epsilon: 0.3670\n",
      "Episode: 200, Total Reward: 310.0, Epsilon: 0.3651\n",
      "Episode: 201, Total Reward: 410.0, Epsilon: 0.3633\n",
      "Episode: 202, Total Reward: 270.0, Epsilon: 0.3615\n",
      "Episode: 203, Total Reward: 1140.0, Epsilon: 0.3597\n",
      "Episode: 204, Total Reward: 240.0, Epsilon: 0.3579\n",
      "Episode: 205, Total Reward: 230.0, Epsilon: 0.3561\n",
      "Episode: 206, Total Reward: 620.0, Epsilon: 0.3543\n",
      "Episode: 207, Total Reward: 530.0, Epsilon: 0.3525\n",
      "Episode: 208, Total Reward: 210.0, Epsilon: 0.3508\n",
      "Episode: 209, Total Reward: 420.0, Epsilon: 0.3490\n",
      "Episode: 210, Total Reward: 260.0, Epsilon: 0.3473\n",
      "Episode: 211, Total Reward: 350.0, Epsilon: 0.3455\n",
      "Episode: 212, Total Reward: 260.0, Epsilon: 0.3438\n",
      "Episode: 213, Total Reward: 270.0, Epsilon: 0.3421\n",
      "Episode: 214, Total Reward: 330.0, Epsilon: 0.3404\n",
      "Episode: 215, Total Reward: 480.0, Epsilon: 0.3387\n",
      "Episode: 216, Total Reward: 1030.0, Epsilon: 0.3370\n",
      "Episode: 217, Total Reward: 370.0, Epsilon: 0.3353\n",
      "Episode: 218, Total Reward: 370.0, Epsilon: 0.3336\n",
      "Episode: 219, Total Reward: 370.0, Epsilon: 0.3320\n",
      "Episode: 220, Total Reward: 380.0, Epsilon: 0.3303\n",
      "Episode: 221, Total Reward: 350.0, Epsilon: 0.3286\n",
      "Episode: 222, Total Reward: 250.0, Epsilon: 0.3270\n",
      "Episode: 223, Total Reward: 300.0, Epsilon: 0.3254\n",
      "Episode: 224, Total Reward: 350.0, Epsilon: 0.3237\n",
      "Episode: 225, Total Reward: 200.0, Epsilon: 0.3221\n",
      "Episode: 226, Total Reward: 270.0, Epsilon: 0.3205\n",
      "Episode: 227, Total Reward: 320.0, Epsilon: 0.3189\n",
      "Episode: 228, Total Reward: 300.0, Epsilon: 0.3173\n",
      "Episode: 229, Total Reward: 350.0, Epsilon: 0.3157\n",
      "Episode: 230, Total Reward: 290.0, Epsilon: 0.3141\n",
      "Episode: 231, Total Reward: 790.0, Epsilon: 0.3126\n",
      "Episode: 232, Total Reward: 370.0, Epsilon: 0.3110\n",
      "Episode: 233, Total Reward: 510.0, Epsilon: 0.3095\n",
      "Episode: 234, Total Reward: 680.0, Epsilon: 0.3079\n",
      "Episode: 235, Total Reward: 440.0, Epsilon: 0.3064\n",
      "Episode: 236, Total Reward: 380.0, Epsilon: 0.3048\n",
      "Episode: 237, Total Reward: 290.0, Epsilon: 0.3033\n",
      "Episode: 238, Total Reward: 1030.0, Epsilon: 0.3018\n",
      "Episode: 239, Total Reward: 410.0, Epsilon: 0.3003\n",
      "Episode: 240, Total Reward: 1050.0, Epsilon: 0.2988\n",
      "Episode: 241, Total Reward: 200.0, Epsilon: 0.2973\n",
      "Episode: 242, Total Reward: 230.0, Epsilon: 0.2958\n",
      "Episode: 243, Total Reward: 940.0, Epsilon: 0.2943\n",
      "Episode: 244, Total Reward: 610.0, Epsilon: 0.2929\n",
      "Episode: 245, Total Reward: 260.0, Epsilon: 0.2914\n",
      "Episode: 246, Total Reward: 320.0, Epsilon: 0.2899\n",
      "Episode: 247, Total Reward: 540.0, Epsilon: 0.2885\n",
      "Episode: 248, Total Reward: 530.0, Epsilon: 0.2870\n",
      "Episode: 249, Total Reward: 200.0, Epsilon: 0.2856\n",
      "Episode: 250, Total Reward: 270.0, Epsilon: 0.2842\n",
      "Episode: 251, Total Reward: 300.0, Epsilon: 0.2828\n",
      "Episode: 252, Total Reward: 250.0, Epsilon: 0.2813\n",
      "Episode: 253, Total Reward: 350.0, Epsilon: 0.2799\n",
      "Episode: 254, Total Reward: 320.0, Epsilon: 0.2785\n",
      "Episode: 255, Total Reward: 410.0, Epsilon: 0.2771\n",
      "Episode: 256, Total Reward: 410.0, Epsilon: 0.2758\n",
      "Episode: 257, Total Reward: 260.0, Epsilon: 0.2744\n",
      "Episode: 258, Total Reward: 290.0, Epsilon: 0.2730\n",
      "Episode: 259, Total Reward: 390.0, Epsilon: 0.2716\n",
      "Episode: 260, Total Reward: 310.0, Epsilon: 0.2703\n",
      "Episode: 261, Total Reward: 360.0, Epsilon: 0.2689\n",
      "Episode: 262, Total Reward: 330.0, Epsilon: 0.2676\n",
      "Episode: 263, Total Reward: 310.0, Epsilon: 0.2663\n",
      "Episode: 264, Total Reward: 790.0, Epsilon: 0.2649\n",
      "Episode: 265, Total Reward: 270.0, Epsilon: 0.2636\n",
      "Episode: 266, Total Reward: 350.0, Epsilon: 0.2623\n",
      "Episode: 267, Total Reward: 1100.0, Epsilon: 0.2610\n",
      "Episode: 268, Total Reward: 740.0, Epsilon: 0.2597\n",
      "Episode: 269, Total Reward: 1250.0, Epsilon: 0.2584\n",
      "Episode: 270, Total Reward: 430.0, Epsilon: 0.2571\n",
      "Episode: 271, Total Reward: 550.0, Epsilon: 0.2558\n",
      "Episode: 272, Total Reward: 210.0, Epsilon: 0.2545\n",
      "Episode: 273, Total Reward: 470.0, Epsilon: 0.2532\n",
      "Episode: 274, Total Reward: 670.0, Epsilon: 0.2520\n",
      "Episode: 275, Total Reward: 690.0, Epsilon: 0.2507\n",
      "Episode: 276, Total Reward: 500.0, Epsilon: 0.2495\n",
      "Episode: 277, Total Reward: 300.0, Epsilon: 0.2482\n",
      "Episode: 278, Total Reward: 520.0, Epsilon: 0.2470\n",
      "Episode: 279, Total Reward: 250.0, Epsilon: 0.2457\n",
      "Episode: 280, Total Reward: 450.0, Epsilon: 0.2445\n",
      "Episode: 281, Total Reward: 220.0, Epsilon: 0.2433\n",
      "Episode: 282, Total Reward: 1100.0, Epsilon: 0.2421\n",
      "Episode: 283, Total Reward: 200.0, Epsilon: 0.2409\n",
      "Episode: 284, Total Reward: 330.0, Epsilon: 0.2397\n",
      "Episode: 285, Total Reward: 380.0, Epsilon: 0.2385\n",
      "Episode: 286, Total Reward: 300.0, Epsilon: 0.2373\n",
      "Episode: 287, Total Reward: 230.0, Epsilon: 0.2361\n",
      "Episode: 288, Total Reward: 370.0, Epsilon: 0.2349\n",
      "Episode: 289, Total Reward: 480.0, Epsilon: 0.2337\n",
      "Episode: 290, Total Reward: 580.0, Epsilon: 0.2326\n",
      "Episode: 291, Total Reward: 1680.0, Epsilon: 0.2314\n",
      "Episode: 292, Total Reward: 370.0, Epsilon: 0.2302\n",
      "Episode: 293, Total Reward: 210.0, Epsilon: 0.2291\n",
      "Episode: 294, Total Reward: 460.0, Epsilon: 0.2279\n",
      "Episode: 295, Total Reward: 260.0, Epsilon: 0.2268\n",
      "Episode: 296, Total Reward: 540.0, Epsilon: 0.2257\n",
      "Episode: 297, Total Reward: 360.0, Epsilon: 0.2245\n",
      "Episode: 298, Total Reward: 250.0, Epsilon: 0.2234\n",
      "Episode: 299, Total Reward: 340.0, Epsilon: 0.2223\n",
      "Episode: 300, Total Reward: 280.0, Epsilon: 0.2212\n",
      "Episode: 301, Total Reward: 260.0, Epsilon: 0.2201\n",
      "Episode: 302, Total Reward: 450.0, Epsilon: 0.2190\n",
      "Episode: 303, Total Reward: 2020.0, Epsilon: 0.2179\n",
      "Episode: 304, Total Reward: 280.0, Epsilon: 0.2168\n",
      "Episode: 305, Total Reward: 300.0, Epsilon: 0.2157\n",
      "Episode: 306, Total Reward: 370.0, Epsilon: 0.2146\n",
      "Episode: 307, Total Reward: 480.0, Epsilon: 0.2136\n",
      "Episode: 308, Total Reward: 470.0, Epsilon: 0.2125\n",
      "Episode: 309, Total Reward: 290.0, Epsilon: 0.2114\n",
      "Episode: 310, Total Reward: 400.0, Epsilon: 0.2104\n",
      "Episode: 311, Total Reward: 300.0, Epsilon: 0.2093\n",
      "Episode: 312, Total Reward: 300.0, Epsilon: 0.2083\n",
      "Episode: 313, Total Reward: 340.0, Epsilon: 0.2072\n",
      "Episode: 314, Total Reward: 230.0, Epsilon: 0.2062\n",
      "Episode: 315, Total Reward: 290.0, Epsilon: 0.2052\n",
      "Episode: 316, Total Reward: 1180.0, Epsilon: 0.2041\n",
      "Episode: 317, Total Reward: 380.0, Epsilon: 0.2031\n",
      "Episode: 318, Total Reward: 350.0, Epsilon: 0.2021\n",
      "Episode: 319, Total Reward: 1000.0, Epsilon: 0.2011\n",
      "Episode: 320, Total Reward: 870.0, Epsilon: 0.2001\n",
      "Episode: 321, Total Reward: 420.0, Epsilon: 0.1991\n",
      "Episode: 322, Total Reward: 370.0, Epsilon: 0.1981\n",
      "Episode: 323, Total Reward: 1200.0, Epsilon: 0.1971\n",
      "Episode: 324, Total Reward: 450.0, Epsilon: 0.1961\n",
      "Episode: 325, Total Reward: 370.0, Epsilon: 0.1951\n",
      "Episode: 326, Total Reward: 410.0, Epsilon: 0.1942\n",
      "Episode: 327, Total Reward: 540.0, Epsilon: 0.1932\n",
      "Episode: 328, Total Reward: 230.0, Epsilon: 0.1922\n",
      "Episode: 329, Total Reward: 680.0, Epsilon: 0.1913\n",
      "Episode: 330, Total Reward: 670.0, Epsilon: 0.1903\n",
      "Episode: 331, Total Reward: 480.0, Epsilon: 0.1893\n",
      "Episode: 332, Total Reward: 500.0, Epsilon: 0.1884\n",
      "Episode: 333, Total Reward: 320.0, Epsilon: 0.1875\n",
      "Episode: 334, Total Reward: 1030.0, Epsilon: 0.1865\n",
      "Episode: 335, Total Reward: 640.0, Epsilon: 0.1856\n",
      "Episode: 336, Total Reward: 450.0, Epsilon: 0.1847\n",
      "Episode: 337, Total Reward: 420.0, Epsilon: 0.1837\n",
      "Episode: 338, Total Reward: 440.0, Epsilon: 0.1828\n",
      "Episode: 339, Total Reward: 170.0, Epsilon: 0.1819\n",
      "Episode: 340, Total Reward: 400.0, Epsilon: 0.1810\n",
      "Episode: 341, Total Reward: 940.0, Epsilon: 0.1801\n",
      "Episode: 342, Total Reward: 290.0, Epsilon: 0.1792\n",
      "Episode: 343, Total Reward: 330.0, Epsilon: 0.1783\n",
      "Episode: 344, Total Reward: 680.0, Epsilon: 0.1774\n",
      "Episode: 345, Total Reward: 360.0, Epsilon: 0.1765\n",
      "Episode: 346, Total Reward: 290.0, Epsilon: 0.1756\n",
      "Episode: 347, Total Reward: 280.0, Epsilon: 0.1748\n",
      "Episode: 348, Total Reward: 290.0, Epsilon: 0.1739\n",
      "Episode: 349, Total Reward: 360.0, Epsilon: 0.1730\n",
      "Episode: 350, Total Reward: 720.0, Epsilon: 0.1721\n",
      "Episode: 351, Total Reward: 280.0, Epsilon: 0.1713\n",
      "Episode: 352, Total Reward: 450.0, Epsilon: 0.1704\n",
      "Episode: 353, Total Reward: 300.0, Epsilon: 0.1696\n",
      "Episode: 354, Total Reward: 270.0, Epsilon: 0.1687\n",
      "Episode: 355, Total Reward: 640.0, Epsilon: 0.1679\n",
      "Episode: 356, Total Reward: 330.0, Epsilon: 0.1670\n",
      "Episode: 357, Total Reward: 1130.0, Epsilon: 0.1662\n",
      "Episode: 358, Total Reward: 350.0, Epsilon: 0.1654\n",
      "Episode: 359, Total Reward: 510.0, Epsilon: 0.1646\n",
      "Episode: 360, Total Reward: 260.0, Epsilon: 0.1637\n",
      "Episode: 361, Total Reward: 330.0, Epsilon: 0.1629\n",
      "Episode: 362, Total Reward: 270.0, Epsilon: 0.1621\n",
      "Episode: 363, Total Reward: 330.0, Epsilon: 0.1613\n",
      "Episode: 364, Total Reward: 290.0, Epsilon: 0.1605\n",
      "Episode: 365, Total Reward: 600.0, Epsilon: 0.1597\n",
      "Episode: 366, Total Reward: 220.0, Epsilon: 0.1589\n",
      "Episode: 367, Total Reward: 320.0, Epsilon: 0.1581\n",
      "Episode: 368, Total Reward: 550.0, Epsilon: 0.1573\n",
      "Episode: 369, Total Reward: 290.0, Epsilon: 0.1565\n",
      "Episode: 370, Total Reward: 300.0, Epsilon: 0.1557\n",
      "Episode: 371, Total Reward: 370.0, Epsilon: 0.1549\n",
      "Episode: 372, Total Reward: 380.0, Epsilon: 0.1542\n",
      "Episode: 373, Total Reward: 710.0, Epsilon: 0.1534\n",
      "Episode: 374, Total Reward: 500.0, Epsilon: 0.1526\n",
      "Episode: 375, Total Reward: 240.0, Epsilon: 0.1519\n",
      "Episode: 376, Total Reward: 850.0, Epsilon: 0.1511\n",
      "Episode: 377, Total Reward: 530.0, Epsilon: 0.1504\n",
      "Episode: 378, Total Reward: 680.0, Epsilon: 0.1496\n",
      "Episode: 379, Total Reward: 240.0, Epsilon: 0.1489\n",
      "Episode: 380, Total Reward: 320.0, Epsilon: 0.1481\n",
      "Episode: 381, Total Reward: 410.0, Epsilon: 0.1474\n",
      "Episode: 382, Total Reward: 320.0, Epsilon: 0.1466\n",
      "Episode: 383, Total Reward: 910.0, Epsilon: 0.1459\n",
      "Episode: 384, Total Reward: 1220.0, Epsilon: 0.1452\n",
      "Episode: 385, Total Reward: 400.0, Epsilon: 0.1444\n",
      "Episode: 386, Total Reward: 1000.0, Epsilon: 0.1437\n",
      "Episode: 387, Total Reward: 510.0, Epsilon: 0.1430\n",
      "Episode: 388, Total Reward: 840.0, Epsilon: 0.1423\n",
      "Episode: 389, Total Reward: 570.0, Epsilon: 0.1416\n",
      "Episode: 390, Total Reward: 390.0, Epsilon: 0.1409\n",
      "Episode: 391, Total Reward: 370.0, Epsilon: 0.1402\n",
      "Episode: 392, Total Reward: 550.0, Epsilon: 0.1395\n",
      "Episode: 393, Total Reward: 330.0, Epsilon: 0.1388\n",
      "Episode: 394, Total Reward: 360.0, Epsilon: 0.1381\n",
      "Episode: 395, Total Reward: 1120.0, Epsilon: 0.1374\n",
      "Episode: 396, Total Reward: 730.0, Epsilon: 0.1367\n",
      "Episode: 397, Total Reward: 650.0, Epsilon: 0.1360\n",
      "Episode: 398, Total Reward: 220.0, Epsilon: 0.1353\n",
      "Episode: 399, Total Reward: 470.0, Epsilon: 0.1347\n",
      "Episode: 400, Total Reward: 80.0, Epsilon: 0.1340\n",
      "Episode: 401, Total Reward: 240.0, Epsilon: 0.1333\n",
      "Episode: 402, Total Reward: 360.0, Epsilon: 0.1326\n",
      "Episode: 403, Total Reward: 230.0, Epsilon: 0.1320\n",
      "Episode: 404, Total Reward: 570.0, Epsilon: 0.1313\n",
      "Episode: 405, Total Reward: 1290.0, Epsilon: 0.1307\n",
      "Episode: 406, Total Reward: 280.0, Epsilon: 0.1300\n",
      "Episode: 407, Total Reward: 460.0, Epsilon: 0.1294\n",
      "Episode: 408, Total Reward: 340.0, Epsilon: 0.1287\n",
      "Episode: 409, Total Reward: 650.0, Epsilon: 0.1281\n",
      "Episode: 410, Total Reward: 580.0, Epsilon: 0.1274\n",
      "Episode: 411, Total Reward: 360.0, Epsilon: 0.1268\n",
      "Episode: 412, Total Reward: 650.0, Epsilon: 0.1262\n",
      "Episode: 413, Total Reward: 320.0, Epsilon: 0.1255\n",
      "Episode: 414, Total Reward: 380.0, Epsilon: 0.1249\n",
      "Episode: 415, Total Reward: 300.0, Epsilon: 0.1243\n",
      "Episode: 416, Total Reward: 290.0, Epsilon: 0.1237\n",
      "Episode: 417, Total Reward: 620.0, Epsilon: 0.1230\n",
      "Episode: 418, Total Reward: 220.0, Epsilon: 0.1224\n",
      "Episode: 419, Total Reward: 1150.0, Epsilon: 0.1218\n",
      "Episode: 420, Total Reward: 260.0, Epsilon: 0.1212\n",
      "Episode: 421, Total Reward: 400.0, Epsilon: 0.1206\n",
      "Episode: 422, Total Reward: 250.0, Epsilon: 0.1200\n",
      "Episode: 423, Total Reward: 200.0, Epsilon: 0.1194\n",
      "Episode: 424, Total Reward: 520.0, Epsilon: 0.1188\n",
      "Episode: 425, Total Reward: 500.0, Epsilon: 0.1182\n",
      "Episode: 426, Total Reward: 280.0, Epsilon: 0.1176\n",
      "Episode: 427, Total Reward: 610.0, Epsilon: 0.1170\n",
      "Episode: 428, Total Reward: 290.0, Epsilon: 0.1164\n",
      "Episode: 429, Total Reward: 690.0, Epsilon: 0.1159\n",
      "Episode: 430, Total Reward: 280.0, Epsilon: 0.1153\n",
      "Episode: 431, Total Reward: 1170.0, Epsilon: 0.1147\n",
      "Episode: 432, Total Reward: 300.0, Epsilon: 0.1141\n",
      "Episode: 433, Total Reward: 790.0, Epsilon: 0.1136\n",
      "Episode: 434, Total Reward: 520.0, Epsilon: 0.1130\n",
      "Episode: 435, Total Reward: 200.0, Epsilon: 0.1124\n",
      "Episode: 436, Total Reward: 250.0, Epsilon: 0.1119\n",
      "Episode: 437, Total Reward: 360.0, Epsilon: 0.1113\n",
      "Episode: 438, Total Reward: 1550.0, Epsilon: 0.1107\n",
      "Episode: 439, Total Reward: 670.0, Epsilon: 0.1102\n",
      "Episode: 440, Total Reward: 420.0, Epsilon: 0.1096\n",
      "Episode: 441, Total Reward: 530.0, Epsilon: 0.1091\n",
      "Episode: 442, Total Reward: 410.0, Epsilon: 0.1085\n",
      "Episode: 443, Total Reward: 400.0, Epsilon: 0.1080\n",
      "Episode: 444, Total Reward: 920.0, Epsilon: 0.1075\n",
      "Episode: 445, Total Reward: 690.0, Epsilon: 0.1069\n",
      "Episode: 446, Total Reward: 380.0, Epsilon: 0.1064\n",
      "Episode: 447, Total Reward: 1090.0, Epsilon: 0.1059\n",
      "Episode: 448, Total Reward: 560.0, Epsilon: 0.1053\n",
      "Episode: 449, Total Reward: 360.0, Epsilon: 0.1048\n",
      "Episode: 450, Total Reward: 420.0, Epsilon: 0.1043\n",
      "Episode: 451, Total Reward: 310.0, Epsilon: 0.1038\n",
      "Episode: 452, Total Reward: 300.0, Epsilon: 0.1032\n",
      "Episode: 453, Total Reward: 570.0, Epsilon: 0.1027\n",
      "Episode: 454, Total Reward: 750.0, Epsilon: 0.1022\n",
      "Episode: 455, Total Reward: 950.0, Epsilon: 0.1017\n",
      "Episode: 456, Total Reward: 940.0, Epsilon: 0.1012\n",
      "Episode: 457, Total Reward: 270.0, Epsilon: 0.1007\n",
      "Episode: 458, Total Reward: 900.0, Epsilon: 0.1002\n",
      "Episode: 459, Total Reward: 410.0, Epsilon: 0.0997\n",
      "Episode: 460, Total Reward: 400.0, Epsilon: 0.0997\n",
      "Episode: 461, Total Reward: 1230.0, Epsilon: 0.0997\n",
      "Episode: 462, Total Reward: 540.0, Epsilon: 0.0997\n",
      "Episode: 463, Total Reward: 740.0, Epsilon: 0.0997\n",
      "Episode: 464, Total Reward: 350.0, Epsilon: 0.0997\n",
      "Episode: 465, Total Reward: 650.0, Epsilon: 0.0997\n",
      "Episode: 466, Total Reward: 600.0, Epsilon: 0.0997\n",
      "Episode: 467, Total Reward: 670.0, Epsilon: 0.0997\n",
      "Episode: 468, Total Reward: 510.0, Epsilon: 0.0997\n",
      "Episode: 469, Total Reward: 530.0, Epsilon: 0.0997\n",
      "Episode: 470, Total Reward: 310.0, Epsilon: 0.0997\n",
      "Episode: 471, Total Reward: 400.0, Epsilon: 0.0997\n",
      "Episode: 472, Total Reward: 340.0, Epsilon: 0.0997\n",
      "Episode: 473, Total Reward: 450.0, Epsilon: 0.0997\n",
      "Episode: 474, Total Reward: 540.0, Epsilon: 0.0997\n",
      "Episode: 475, Total Reward: 470.0, Epsilon: 0.0997\n",
      "Episode: 476, Total Reward: 480.0, Epsilon: 0.0997\n",
      "Episode: 477, Total Reward: 550.0, Epsilon: 0.0997\n",
      "Episode: 478, Total Reward: 300.0, Epsilon: 0.0997\n",
      "Episode: 479, Total Reward: 1100.0, Epsilon: 0.0997\n",
      "Episode: 480, Total Reward: 370.0, Epsilon: 0.0997\n",
      "Episode: 481, Total Reward: 360.0, Epsilon: 0.0997\n",
      "Episode: 482, Total Reward: 540.0, Epsilon: 0.0997\n",
      "Episode: 483, Total Reward: 450.0, Epsilon: 0.0997\n",
      "Episode: 484, Total Reward: 1180.0, Epsilon: 0.0997\n",
      "Episode: 485, Total Reward: 250.0, Epsilon: 0.0997\n",
      "Episode: 486, Total Reward: 620.0, Epsilon: 0.0997\n",
      "Episode: 487, Total Reward: 200.0, Epsilon: 0.0997\n",
      "Episode: 488, Total Reward: 320.0, Epsilon: 0.0997\n",
      "Episode: 489, Total Reward: 370.0, Epsilon: 0.0997\n",
      "Episode: 490, Total Reward: 570.0, Epsilon: 0.0997\n",
      "Episode: 491, Total Reward: 320.0, Epsilon: 0.0997\n",
      "Episode: 492, Total Reward: 280.0, Epsilon: 0.0997\n",
      "Episode: 493, Total Reward: 330.0, Epsilon: 0.0997\n",
      "Episode: 494, Total Reward: 760.0, Epsilon: 0.0997\n",
      "Episode: 495, Total Reward: 530.0, Epsilon: 0.0997\n",
      "Episode: 496, Total Reward: 560.0, Epsilon: 0.0997\n",
      "Episode: 497, Total Reward: 270.0, Epsilon: 0.0997\n",
      "Episode: 498, Total Reward: 510.0, Epsilon: 0.0997\n",
      "Episode: 499, Total Reward: 390.0, Epsilon: 0.0997\n"
     ]
    }
   ],
   "source": [
    "state_buffer = []\n",
    "\n",
    "for episode in range(episodes):\n",
    "    reset_result = env.reset()\n",
    "    if isinstance(reset_result, tuple):\n",
    "        state = reset_result[0]\n",
    "    else:\n",
    "        state = reset_result\n",
    "    \n",
    "    state_buffer.clear()\n",
    "    processed_frame = preprocess(state)\n",
    "    state_buffer = [processed_frame] * 4\n",
    "\n",
    "    total_reward = 0\n",
    "    \n",
    "    for t in range(10000):\n",
    "        stacked_state = np.stack(state_buffer, axis=0)\n",
    "        stacked_state = np.expand_dims(stacked_state, axis=0)\n",
    "        stacked_state = stacked_state.squeeze(0)\n",
    "\n",
    "        action = select_action(stacked_state, epsilon)\n",
    "        \n",
    "        next_step_result = env.step(action)\n",
    "        if isinstance(next_step_result, tuple):\n",
    "            if len(next_step_result) == 5:\n",
    "                next_state, reward, done, truncated, info = next_step_result\n",
    "                done = done or truncated\n",
    "            else:\n",
    "                next_state, reward, done, info = next_step_result\n",
    "        else:\n",
    "            next_state, reward, done, info = next_step_result\n",
    "        \n",
    "        #Adjust the reward based on the reward tier system\n",
    "        reward = adjust_reward(reward, info)\n",
    "\n",
    "        processed_next_frame = preprocess(next_state)\n",
    "        next_state_buffer = state_buffer[1:] + [processed_next_frame]\n",
    "        \n",
    "        memory.append((np.stack(state_buffer, axis=0), action, reward, np.stack(next_state_buffer, axis=0), done))\n",
    "        if len(memory) > max_memory:\n",
    "            memory.pop(0)\n",
    "        \n",
    "        train()\n",
    "        \n",
    "        state_buffer = next_state_buffer\n",
    "        total_reward += reward\n",
    "        if done:\n",
    "            break\n",
    "    \n",
    "    if epsilon > epsilon_min:\n",
    "        epsilon *= epsilon_decay\n",
    "    \n",
    "    if episode % 10 == 0:\n",
    "        target_dqn.load_state_dict(dqn.state_dict())\n",
    "    \n",
    "    print(f\"Episode: {episode}, Total Reward: {total_reward}, Epsilon: {epsilon:.4f}\")\n",
    "\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
